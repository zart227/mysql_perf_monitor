from jinja2 import Template
from datetime import datetime
import os
import pandas as pd
import io
import re
import logging

logger = logging.getLogger(__name__)

REPORT_TEMPLATE = """
# –û—Ç—á—ë—Ç –ø–æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ MySQL

**–î–∞—Ç–∞:** {{ date }}

## –ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

{% if issues %}
### –ü—Ä–æ–±–ª–µ–º—ã:
{% for issue in issues %}
- {{ issue }}
{% endfor %}
{% else %}
–ö—Ä–∏—Ç–∏—á–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.
{% endif %}

{% if recommendations %}
### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
{% for rec in recommendations %}
- {{ rec }}
{% endfor %}
{% endif %}

---

## –î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏

{% for key, output in metrics.items() %}
{% if key != 'cpu_spikes' %}
### {{ key }}
{% if key in ['global_status', 'global_variables', 'qcache_status', 'processlist'] and '---' in output %}
{{ output }}
{% else %}
```
{{ output }}
```
{% endif %}
{% endif %}
{% endfor %}

{% if metrics.cpu_spikes %}
## –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∏–∫–∞—Ö CPU

{% for spike in metrics.cpu_spikes %}
### –ü–∏–∫ –≤ {{ spike.timestamp }} (CPU: {{ spike.cpu_usage }}%)

**–ü—Ä–æ—Ü–µ—Å—Å-–≤–∏–Ω–æ–≤–Ω–∏–∫:**
```
{{ spike.triggering_process_line }}
```

**–°–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –º–æ–º–µ–Ω—Ç –ø–∏–∫–∞ (`SHOW FULL PROCESSLIST`):**
{{ spike.processlist_output }}
---
{% endfor %}
{% endif %}
"""

BASELINE_TEMPLATE = """
# –ë–∞–∑–æ–≤—ã–π –æ—Ç—á–µ—Ç –æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ MySQL
**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** {{ date }}
---
## –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ CPU
{{ metrics.cpuinfo }}
---
## –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–º—è—Ç–∏
{{ metrics.memory }}
---
## –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ MySQL
{{ metrics.global_variables }}
"""

EVENT_HEADER_TEMPLATE = """
# –ñ—É—Ä–Ω–∞–ª —Å–æ–±—ã—Ç–∏–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞ {{ date }}
"""

CPU_EVENT_TEMPLATE = """
---
### üìà –ü–∏–∫ CPU –≤ {{ time }}
- **PID –ø—Ä–æ—Ü–µ—Å—Å–∞:** `{{ pid }}`
- **–ó–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞:** `{{ cpu_percent }}%`

**–¢–æ–ø-5 –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤ –º–æ–º–µ–Ω—Ç –ø–∏–∫–∞:**
{{ process_list }}
"""

MEMORY_EVENT_TEMPLATE = """
---
### üìâ –í—ã—Å–æ–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ –≤ {{ time }}
- **–ó–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:** `{{ memory_percent }}%`
"""

def parse_innodb_status(status_string):
    """
    –ü–∞—Ä—Å–∏—Ç –≤—ã–≤–æ–¥ SHOW ENGINE INNODB STATUS, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –¥–≤—É—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö:
    1. –¢–∞–±–ª–∏—á–Ω—ã–π (—Å \t –∏ \n)
    2. –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π (—Å \G)
    """
    if "***************************" in status_string:
        # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (\G)
        match = re.search(r'Status:\n(.*?)$', status_string, re.DOTALL)
        if match:
            return match.group(1).strip()
    else:
        # –¢–∞–±–ª–∏—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        parts = status_string.split('\t')
        if len(parts) > 2:
            return parts[2].replace('\\n', '\n').strip()
    
    # Fallback
    return status_string.replace('\\n', '\n').strip()

def to_markdown_table(data):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Å—Ç—Ä–æ–∫–∞ —Å —Ç–∞–±—É–ª—è—Ü–∏–µ–π –∏–ª–∏ markdown) –≤ markdown-—Ç–∞–±–ª–∏—Ü—É."""
    if not data or not isinstance(data, str):
        return data or ''
    # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–∞–±—É–ª—è—Ü–∏–∏, –ø—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ pandas
    if '\t' in data:
        try:
            df = pd.read_csv(io.StringIO(data), sep='\t', engine='python')
            return df.to_markdown(index=False)
        except Exception as e:
            return f"```\n(–æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–∞–±–ª–∏—Ü—ã: {e})\n{data}\n```"
    return data

def parse_and_format_free_output(free_output):
    """–ü–∞—Ä—Å–∏—Ç –≤—ã–≤–æ–¥ 'free -m' –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –µ–≥–æ –≤ –≤–∏–¥–µ markdown-—Ç–∞–±–ª–∏—Ü—ã –∏ —Ç–∞–±–ª–∏—Ü—ã buffers/cache."""
    if not free_output or not isinstance(free_output, str):
        return f"```\n{free_output or 'N/A'}\n```"
    try:
        lines = free_output.strip().splitlines()
        # –û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–∞–º—è—Ç–∏
        main_table = '\n'.join(lines[:3])
        main_table_md = to_markdown_table(main_table)
        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è buffers/cache
        buffer_line = lines[2]
        buffer_parts = buffer_line.split()
        buffer_used = buffer_parts[2]
        buffer_free = buffer_parts[3]
        buffer_df = pd.DataFrame([
            {"–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å": "Used (-buffers/cache)", "–ó–Ω–∞—á–µ–Ω–∏–µ (MB)": buffer_used},
            {"–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å": "Free (+buffers/cache)", "–ó–Ω–∞—á–µ–Ω–∏–µ (MB)": buffer_free}
        ])
        table2 = buffer_df.to_markdown(index=False)
        return f"{main_table_md}\n\n**–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ `-/+ buffers/cache`:**\n{table2}"
    except Exception as e:
        return f"```\n(–æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ 'free -m': {e})\n{free_output}\n```"

def parse_and_format_cpuinfo(cpuinfo_output):
    """–ü–∞—Ä—Å–∏—Ç –≤—ã–≤–æ–¥ /proc/cpuinfo –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –≤ —Ç–∞–±–ª–∏—Ü—É "–ü–∞—Ä–∞–º–µ—Ç—Ä-–ó–Ω–∞—á–µ–Ω–∏–µ"."""
    if not cpuinfo_output or not isinstance(cpuinfo_output, str):
        return f"```\n{cpuinfo_output or 'N/A'}\n```"
    try:
        # --- –ë–ª–æ–∫ –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Ç–æ–ª—å–∫–æ –ø–æ –ø–µ—Ä–≤–æ–º—É –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—É ---
        processor_blocks = cpuinfo_output.strip().split('\n\n')
        first_block = ""
        for block in processor_blocks:
            if block.strip():
                first_block = block
                break
        
        if not first_block.strip():
            processor_lines = cpuinfo_output.strip().split('\n')
            first_block_lines = []
            for line in processor_lines:
                if not line.strip() and first_block_lines:
                    break
                first_block_lines.append(line)
            first_block = "\n".join(first_block_lines)

        if not first_block.strip():
             return f"```\n(–Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –±–ª–æ–∫ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –≤ cpuinfo)\n{cpuinfo_output}\n```"
        # --- –ö–æ–Ω–µ—Ü –±–ª–æ–∫–∞ ---

        params = []
        values = []
        for line in first_block.split('\n'):
            if ':' in line:
                parts = line.split(':', 1)
                key = parts[0].strip()
                value = parts[1].strip()
                params.append(key)
                values.append(value)

        if not params:
            return f"```\n(–Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å cpuinfo)\n{cpuinfo_output}\n```"

        df = pd.DataFrame({
            '–ü–∞—Ä–∞–º–µ—Ç—Ä': params,
            '–ó–Ω–∞—á–µ–Ω–∏–µ': values
        })
        
        return df.to_markdown(index=False)
    except Exception as e:
        return f"```\n(–æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ cpuinfo: {e})\n{cpuinfo_output}\n```"

def generate_report(metrics, issues, recommendations, output_path=None):
    processed_metrics = metrics.copy()
    
    table_alignments = {
        'global_status': ("left", "left"),
        'global_variables': ("left", "left"),
        'qcache_status': ("left", "right"),
        'processlist': ("right", "left", "left", "center", "left", "right", "center", "left")
    }
    
    table_keys = list(table_alignments.keys())
    
    for key, value in processed_metrics.items():
        if not value or not isinstance(value, str):
            continue

        if key in table_keys and '\t' in value:
            try:
                df = pd.read_csv(io.StringIO(value), sep='\\t', engine='python')
                colalign = table_alignments.get(key)
                if colalign and len(df.columns) != len(colalign):
                    colalign = None # Fallback to default if column count mismatches
                processed_metrics[key] = df.to_markdown(index=False, colalign=colalign)
            except Exception:
                processed_metrics[key] = f"```\n{value}\n```"

        elif key == 'innodb_status':
            processed_metrics[key] = parse_innodb_status(value)

    if 'cpu_spikes' in processed_metrics:
        for spike in processed_metrics.get('cpu_spikes', []):
            proc_list = spike.get('processlist_output')
            if proc_list and isinstance(proc_list, str) and '\t' in proc_list:
                try:
                    df = pd.read_csv(io.StringIO(proc_list), sep='\\t', engine='python')
                    colalign = table_alignments.get('processlist')
                    if colalign and len(df.columns) != len(colalign):
                        colalign = None # Fallback to default
                    spike['processlist_output'] = df.to_markdown(index=False, colalign=colalign)
                except Exception:
                    spike['processlist_output'] = f"```\n{proc_list}\n```"

    template = Template(REPORT_TEMPLATE)
    report = template.render(
        date=datetime.now().strftime('%Y-%m-%d %H:%M'),
        metrics=processed_metrics,
        issues=issues,
        recommendations=recommendations
    )
    if output_path:
        abs_path = os.path.join(os.getcwd(), output_path) if not os.path.isabs(output_path) else output_path
        os.makedirs(os.path.dirname(abs_path), exist_ok=True)
        with open(abs_path, 'w', encoding='utf-8') as f:
            f.write(report)
    return report 

def generate_baseline_report(metrics, output_path):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–π –æ—Ç—á–µ—Ç —Å cpuinfo, memory –∏ global_variables."""
    processed_metrics = {
        'cpuinfo': parse_and_format_cpuinfo(metrics.get('cpuinfo', 'N/A')),
        'memory': parse_and_format_free_output(metrics.get('memory', 'N/A')),
        'global_variables': to_markdown_table(metrics.get('global_variables'))
    }

    template = Template(BASELINE_TEMPLATE)
    report = template.render(
        date=datetime.now().strftime('%Y-%m-%d %H:%M'),
        metrics=processed_metrics
    )
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report)

def _ensure_header(report_path):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª –∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫, –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –∏—Ö –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏."""
    date_str = datetime.now().strftime('%Y-%m-%d')
    header = Template(EVENT_HEADER_TEMPLATE).render(date=date_str)
    
    if not os.path.exists(report_path):
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(header)
            f.write('\n')

def append_cpu_event_to_report(event_data, report_path):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∏–∫–µ CPU –≤ –æ—Ç—á–µ—Ç –æ —Å–æ–±—ã—Ç–∏—è—Ö."""
    try:
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        os.makedirs(os.path.dirname(report_path), exist_ok=True)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª
        if not os.path.exists(report_path):
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("# üìä –û—Ç—á–µ—Ç –æ —Å–æ–±—ã—Ç–∏—è—Ö –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ MySQL\n\n")
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
        time_str = event_data['time']
        cpu_usage = event_data['cpu']
        pid = event_data['pid']
        process_list = event_data.get('process_list', '')
        performance_analysis = event_data.get('performance_analysis')
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –æ —Å–æ–±—ã—Ç–∏–∏
        event_entry = f"""
---
### üìà –ü–∏–∫ CPU –≤ {time_str}
- **PID –ø—Ä–æ—Ü–µ—Å—Å–∞:** `{pid}`
- **–ó–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞:** `{cpu_usage}%`

**–¢–æ–ø-5 –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤ –º–æ–º–µ–Ω—Ç –ø–∏–∫–∞:**
{to_markdown_table(process_list)}

"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
        if performance_analysis:
            event_entry += f"""
**üìä –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–æ–≤:**
- **–í—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:** {performance_analysis['total_queries']}
- **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:** {performance_analysis['max_time']} —Å–µ–∫
- **–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:** {performance_analysis['avg_time']:.1f} —Å–µ–∫
- **–ú–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (>10 —Å–µ–∫):** {len(performance_analysis['slow_queries'])}
- **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (>30 —Å–µ–∫):** {len(performance_analysis['critical_queries'])}

"""
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –º–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            if performance_analysis['critical_queries']:
                event_entry += "**üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –º–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã (>30 —Å–µ–∫):**\n"
                for query in performance_analysis['critical_queries']:
                    event_entry += f"- **{query['TIME']} —Å–µ–∫:** {query.get('INFO', 'N/A')[:100]}...\n"
                event_entry += "\n"
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            elif performance_analysis['slow_queries']:
                event_entry += "**‚ö†Ô∏è –ú–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã (>10 —Å–µ–∫):**\n"
                for query in performance_analysis['slow_queries']:
                    event_entry += f"- **{query['TIME']} —Å–µ–∫:** {query.get('INFO', 'N/A')[:100]}...\n"
                event_entry += "\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –≤ —Ñ–∞–π–ª
        with open(report_path, 'a', encoding='utf-8') as f:
            f.write(event_entry)
            
        logger.info(f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∏–∫–µ CPU –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –æ—Ç—á–µ—Ç: {report_path}")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–∏–∫–µ CPU –≤ –æ—Ç—á–µ—Ç: {e}", exc_info=True)

def append_memory_event_to_report(event_data, output_path):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –≤ –æ—Ç—á–µ—Ç —Å–æ–±—ã—Ç–∏–µ –æ –≤—ã—Å–æ–∫–æ–º –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–∏ –ø–∞–º—è—Ç–∏."""
    _ensure_header(output_path)
    
    template = Template(MEMORY_EVENT_TEMPLATE)
    report_content = template.render(
        time=event_data['time'],
        memory_percent=event_data['memory_percent']
    )
    
    with open(output_path, 'a', encoding='utf-8') as f:
        f.write(report_content)

def check_if_memory_event_exists(report_path):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –±—ã–ª–æ –ª–∏ —É–∂–µ —Å–µ–≥–æ–¥–Ω—è —Å–æ–±—ã—Ç–∏–µ –ø–æ –ø–∞–º—è—Ç–∏."""
    if not os.path.exists(report_path):
        return False
    with open(report_path, 'r', encoding='utf-8') as f:
        content = f.read()
    return '–í—ã—Å–æ–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏' in content 